{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet19 import *\n",
    "from lib.image_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "input_height, input_width = (224, 224)\n",
    "item_path = \"./items\"\n",
    "background_path = \"./backgrounds\"\n",
    "label_file = \"./data/label.txt\"\n",
    "backup_path = \"backup\"\n",
    "batch_size = 32\n",
    "max_batches = 3000\n",
    "learning_rate = 0.001\n",
    "lr_decay_power = 4\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading image generator...\n"
     ]
    }
   ],
   "source": [
    "# load image generator\n",
    "print(\"loading image generator...\")\n",
    "generator = ImageGenerator(item_path, background_path)\n",
    "\n",
    "with open(label_file, \"r\") as f:\n",
    "    labels = f.read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "print(\"loading model...\")\n",
    "model = Darknet19(num_classes=10, phase='train')\n",
    "\n",
    "# Load Weight\n",
    "# weight_path = ''\n",
    "# model.load_state_dict(weight_path)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr_scheduler(optimizer, batch, lr_decay_power):    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = learning_rate * (1 - batch / max_batches) ** lr_decay_power\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "[batch 1 (32 images)] learning rate: 0.001000, loss: 0.089223, accuracy: 0.125000\n",
      "[batch 2 (64 images)] learning rate: 0.001000, loss: 0.090154, accuracy: 0.031250\n",
      "[batch 3 (96 images)] learning rate: 0.000999, loss: 0.090184, accuracy: 0.093750\n",
      "[batch 4 (128 images)] learning rate: 0.000997, loss: 0.089799, accuracy: 0.125000\n",
      "[batch 5 (160 images)] learning rate: 0.000996, loss: 0.089992, accuracy: 0.125000\n",
      "[batch 6 (192 images)] learning rate: 0.000995, loss: 0.090304, accuracy: 0.062500\n",
      "[batch 7 (224 images)] learning rate: 0.000993, loss: 0.090156, accuracy: 0.093750\n",
      "[batch 8 (256 images)] learning rate: 0.000992, loss: 0.090243, accuracy: 0.062500\n",
      "[batch 9 (288 images)] learning rate: 0.000991, loss: 0.090087, accuracy: 0.062500\n",
      "[batch 10 (320 images)] learning rate: 0.000989, loss: 0.090012, accuracy: 0.125000\n",
      "[batch 11 (352 images)] learning rate: 0.000988, loss: 0.090296, accuracy: 0.031250\n",
      "[batch 12 (384 images)] learning rate: 0.000987, loss: 0.090193, accuracy: 0.093750\n",
      "[batch 13 (416 images)] learning rate: 0.000985, loss: 0.090356, accuracy: 0.000000\n",
      "[batch 14 (448 images)] learning rate: 0.000984, loss: 0.090511, accuracy: 0.125000\n",
      "[batch 15 (480 images)] learning rate: 0.000983, loss: 0.089238, accuracy: 0.250000\n",
      "[batch 16 (512 images)] learning rate: 0.000981, loss: 0.090110, accuracy: 0.031250\n",
      "[batch 17 (544 images)] learning rate: 0.000980, loss: 0.090086, accuracy: 0.093750\n",
      "[batch 18 (576 images)] learning rate: 0.000979, loss: 0.089708, accuracy: 0.156250\n",
      "[batch 19 (608 images)] learning rate: 0.000978, loss: 0.090218, accuracy: 0.125000\n",
      "[batch 20 (640 images)] learning rate: 0.000976, loss: 0.090074, accuracy: 0.093750\n",
      "[batch 21 (672 images)] learning rate: 0.000975, loss: 0.089636, accuracy: 0.187500\n",
      "[batch 22 (704 images)] learning rate: 0.000974, loss: 0.090298, accuracy: 0.031250\n",
      "[batch 23 (736 images)] learning rate: 0.000972, loss: 0.089767, accuracy: 0.187500\n",
      "[batch 24 (768 images)] learning rate: 0.000971, loss: 0.090230, accuracy: 0.031250\n",
      "[batch 25 (800 images)] learning rate: 0.000970, loss: 0.089667, accuracy: 0.093750\n",
      "[batch 26 (832 images)] learning rate: 0.000968, loss: 0.090194, accuracy: 0.062500\n",
      "[batch 27 (864 images)] learning rate: 0.000967, loss: 0.089846, accuracy: 0.125000\n",
      "[batch 28 (896 images)] learning rate: 0.000966, loss: 0.089473, accuracy: 0.156250\n",
      "[batch 29 (928 images)] learning rate: 0.000964, loss: 0.090133, accuracy: 0.031250\n",
      "[batch 30 (960 images)] learning rate: 0.000963, loss: 0.089202, accuracy: 0.125000\n",
      "[batch 31 (992 images)] learning rate: 0.000962, loss: 0.090485, accuracy: 0.093750\n",
      "[batch 32 (1024 images)] learning rate: 0.000961, loss: 0.090209, accuracy: 0.031250\n",
      "[batch 33 (1056 images)] learning rate: 0.000959, loss: 0.090064, accuracy: 0.125000\n",
      "[batch 34 (1088 images)] learning rate: 0.000958, loss: 0.089512, accuracy: 0.187500\n",
      "[batch 35 (1120 images)] learning rate: 0.000957, loss: 0.089898, accuracy: 0.156250\n",
      "[batch 36 (1152 images)] learning rate: 0.000955, loss: 0.089944, accuracy: 0.062500\n",
      "[batch 37 (1184 images)] learning rate: 0.000954, loss: 0.089465, accuracy: 0.281250\n",
      "[batch 38 (1216 images)] learning rate: 0.000953, loss: 0.089826, accuracy: 0.062500\n",
      "[batch 39 (1248 images)] learning rate: 0.000952, loss: 0.090211, accuracy: 0.062500\n",
      "[batch 40 (1280 images)] learning rate: 0.000950, loss: 0.089838, accuracy: 0.093750\n",
      "[batch 41 (1312 images)] learning rate: 0.000949, loss: 0.089595, accuracy: 0.156250\n",
      "[batch 42 (1344 images)] learning rate: 0.000948, loss: 0.090136, accuracy: 0.093750\n",
      "[batch 43 (1376 images)] learning rate: 0.000946, loss: 0.089375, accuracy: 0.218750\n",
      "[batch 44 (1408 images)] learning rate: 0.000945, loss: 0.089651, accuracy: 0.093750\n",
      "[batch 45 (1440 images)] learning rate: 0.000944, loss: 0.090008, accuracy: 0.187500\n",
      "[batch 46 (1472 images)] learning rate: 0.000943, loss: 0.090007, accuracy: 0.062500\n",
      "[batch 47 (1504 images)] learning rate: 0.000941, loss: 0.089200, accuracy: 0.218750\n",
      "[batch 48 (1536 images)] learning rate: 0.000940, loss: 0.090160, accuracy: 0.031250\n",
      "[batch 49 (1568 images)] learning rate: 0.000939, loss: 0.090102, accuracy: 0.000000\n",
      "[batch 50 (1600 images)] learning rate: 0.000938, loss: 0.089971, accuracy: 0.156250\n",
      "[batch 51 (1632 images)] learning rate: 0.000936, loss: 0.089978, accuracy: 0.093750\n",
      "[batch 52 (1664 images)] learning rate: 0.000935, loss: 0.089734, accuracy: 0.156250\n",
      "[batch 53 (1696 images)] learning rate: 0.000934, loss: 0.089359, accuracy: 0.187500\n",
      "[batch 54 (1728 images)] learning rate: 0.000932, loss: 0.090296, accuracy: 0.093750\n",
      "[batch 55 (1760 images)] learning rate: 0.000931, loss: 0.090198, accuracy: 0.031250\n",
      "[batch 56 (1792 images)] learning rate: 0.000930, loss: 0.089429, accuracy: 0.093750\n",
      "[batch 57 (1824 images)] learning rate: 0.000929, loss: 0.089894, accuracy: 0.125000\n",
      "[batch 58 (1856 images)] learning rate: 0.000927, loss: 0.090046, accuracy: 0.125000\n",
      "[batch 59 (1888 images)] learning rate: 0.000926, loss: 0.090029, accuracy: 0.093750\n",
      "[batch 60 (1920 images)] learning rate: 0.000925, loss: 0.090353, accuracy: 0.062500\n",
      "[batch 61 (1952 images)] learning rate: 0.000924, loss: 0.089172, accuracy: 0.156250\n",
      "[batch 62 (1984 images)] learning rate: 0.000922, loss: 0.090028, accuracy: 0.125000\n",
      "[batch 63 (2016 images)] learning rate: 0.000921, loss: 0.089652, accuracy: 0.125000\n",
      "[batch 64 (2048 images)] learning rate: 0.000920, loss: 0.089796, accuracy: 0.125000\n",
      "[batch 65 (2080 images)] learning rate: 0.000919, loss: 0.090175, accuracy: 0.125000\n",
      "[batch 66 (2112 images)] learning rate: 0.000917, loss: 0.090259, accuracy: 0.093750\n",
      "[batch 67 (2144 images)] learning rate: 0.000916, loss: 0.089289, accuracy: 0.156250\n",
      "[batch 68 (2176 images)] learning rate: 0.000915, loss: 0.090213, accuracy: 0.031250\n",
      "[batch 69 (2208 images)] learning rate: 0.000914, loss: 0.089199, accuracy: 0.187500\n",
      "[batch 70 (2240 images)] learning rate: 0.000912, loss: 0.089460, accuracy: 0.093750\n",
      "[batch 71 (2272 images)] learning rate: 0.000911, loss: 0.089296, accuracy: 0.125000\n",
      "[batch 72 (2304 images)] learning rate: 0.000910, loss: 0.089772, accuracy: 0.187500\n",
      "[batch 73 (2336 images)] learning rate: 0.000909, loss: 0.089689, accuracy: 0.156250\n",
      "[batch 74 (2368 images)] learning rate: 0.000907, loss: 0.089736, accuracy: 0.187500\n",
      "[batch 75 (2400 images)] learning rate: 0.000906, loss: 0.089962, accuracy: 0.031250\n",
      "[batch 76 (2432 images)] learning rate: 0.000905, loss: 0.089514, accuracy: 0.093750\n",
      "[batch 77 (2464 images)] learning rate: 0.000904, loss: 0.089820, accuracy: 0.156250\n",
      "[batch 78 (2496 images)] learning rate: 0.000902, loss: 0.089820, accuracy: 0.062500\n",
      "[batch 79 (2528 images)] learning rate: 0.000901, loss: 0.090138, accuracy: 0.062500\n",
      "[batch 80 (2560 images)] learning rate: 0.000900, loss: 0.089193, accuracy: 0.125000\n",
      "[batch 81 (2592 images)] learning rate: 0.000899, loss: 0.089671, accuracy: 0.093750\n",
      "[batch 82 (2624 images)] learning rate: 0.000898, loss: 0.089981, accuracy: 0.187500\n",
      "[batch 83 (2656 images)] learning rate: 0.000896, loss: 0.089862, accuracy: 0.125000\n",
      "[batch 84 (2688 images)] learning rate: 0.000895, loss: 0.089133, accuracy: 0.281250\n",
      "[batch 85 (2720 images)] learning rate: 0.000894, loss: 0.089743, accuracy: 0.062500\n",
      "[batch 86 (2752 images)] learning rate: 0.000893, loss: 0.090452, accuracy: 0.125000\n",
      "[batch 87 (2784 images)] learning rate: 0.000891, loss: 0.089857, accuracy: 0.093750\n",
      "[batch 88 (2816 images)] learning rate: 0.000890, loss: 0.090000, accuracy: 0.062500\n",
      "[batch 89 (2848 images)] learning rate: 0.000889, loss: 0.089751, accuracy: 0.062500\n",
      "[batch 90 (2880 images)] learning rate: 0.000888, loss: 0.089888, accuracy: 0.062500\n",
      "[batch 91 (2912 images)] learning rate: 0.000887, loss: 0.089139, accuracy: 0.218750\n",
      "[batch 92 (2944 images)] learning rate: 0.000885, loss: 0.089079, accuracy: 0.281250\n"
     ]
    }
   ],
   "source": [
    "# start to train\n",
    "print(\"start training\")\n",
    "for batch in range(max_batches):\n",
    "    # generate sample\n",
    "    x, t = generator.generate_samples(\n",
    "        n_samples=batch_size,\n",
    "        n_items=1,\n",
    "        crop_width=input_width,\n",
    "        crop_height=input_height,\n",
    "        min_item_scale=0.3,\n",
    "        max_item_scale=1.05,\n",
    "        rand_angle=25,\n",
    "        minimum_crop=0.8,\n",
    "        delta_hue=0.01,\n",
    "        delta_sat_scale=0.5,\n",
    "        delta_val_scale=0.5\n",
    "    )\n",
    "    x = torch.from_numpy(x)\n",
    "#     x.cuda()\n",
    "    x = Variable(x)\n",
    "    \n",
    "    one_hot_t = []\n",
    "    for i in range(len(t)):\n",
    "        one_hot_t.append(t[i][0][\"one_hot_label\"])\n",
    "    one_hot_t = np.array(one_hot_t, dtype=np.float32)\n",
    "    one_hot_t = torch.from_numpy(one_hot_t)\n",
    "#     one_hot_t.cuda()\n",
    "    one_hot_t = Variable(one_hot_t)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    y = model(x)\n",
    "    loss = criterion(y, one_hot_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    _, pred = torch.max(y.data, 1)\n",
    "    _, answ = torch.max(one_hot_t.data, 1)\n",
    "    accuracy = (pred == answ).sum() / batch_size\n",
    "    \n",
    "    print(\"[batch %d (%d images)] learning rate: %f, loss: %f, accuracy: %f\" % (batch+1, (batch+1) * batch_size, optimizer.param_groups[0]['lr'], loss, accuracy))\n",
    "    \n",
    "    # update lr\n",
    "    optimizer = lr_scheduler(optimizer, batch, lr_decay_power) # Polynomial decay learning rate\n",
    "\n",
    "    # save model\n",
    "    if (batch+1) % 1000 == 0:\n",
    "        model_file = \"%s/%s.pth\" % (backup_path, batch+1)\n",
    "        print(\"saving model to %s\" % (model_file))\n",
    "        torch.save(model.state_dict(), model_file)\n",
    "\n",
    "print(\"saving model to %s/darknet19_final.model\" % (backup_path))\n",
    "torch.save(model.state_dict(), \"%s/darknet19_final.model\" % (backup_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-4.2.0]",
   "language": "python",
   "name": "conda-env-anaconda3-4.2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
