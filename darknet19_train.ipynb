{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet19 import *\n",
    "from lib.image_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "input_height, input_width = (224, 224)\n",
    "item_path = \"./items\"\n",
    "background_path = \"./backgrounds\"\n",
    "label_file = \"./data/label.txt\"\n",
    "backup_path = \"backup\"\n",
    "batch_size = 32\n",
    "max_batches = 3\n",
    "learning_rate = 0.001\n",
    "lr_decay_power = 4\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading image generator...\n"
     ]
    }
   ],
   "source": [
    "# load image generator\n",
    "print(\"loading image generator...\")\n",
    "generator = ImageGenerator(item_path, background_path)\n",
    "\n",
    "with open(label_file, \"r\") as f:\n",
    "    labels = f.read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "print(\"loading model...\")\n",
    "model = Darknet19(num_classes=10, phase='train')\n",
    "\n",
    "# Load Weight\n",
    "# weight_path = ''\n",
    "# model.load_state_dict(weight_path)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr_scheduler(optimizer, batch, lr_decay_power):    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = learning_rate * (1 - batch / max_batches) ** lr_decay_power\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "[batch 1 (32 images)] learning rate: 0.001000, loss: 0.089800, accuracy: 0.125000\n",
      "[batch 2 (64 images)] learning rate: 0.001000, loss: 0.089426, accuracy: 0.125000\n",
      "[batch 3 (96 images)] learning rate: 0.000198, loss: 0.090243, accuracy: 0.093750\n",
      "saving model to backup/darknet19_final.model\n"
     ]
    }
   ],
   "source": [
    "# start to train\n",
    "print(\"start training\")\n",
    "for batch in range(max_batches):\n",
    "    # generate sample\n",
    "    x, t = generator.generate_samples(\n",
    "        n_samples=batch_size,\n",
    "        n_items=1,\n",
    "        crop_width=input_width,\n",
    "        crop_height=input_height,\n",
    "        min_item_scale=0.3,\n",
    "        max_item_scale=1.3,\n",
    "        rand_angle=25,\n",
    "        minimum_crop=0.8,\n",
    "        delta_hue=0.01,\n",
    "        delta_sat_scale=0.5,\n",
    "        delta_val_scale=0.5\n",
    "    )\n",
    "    x = torch.from_numpy(x)\n",
    "#     x.cuda()\n",
    "    x = Variable(x)\n",
    "    \n",
    "    one_hot_t = []\n",
    "    for i in range(len(t)):\n",
    "        one_hot_t.append(t[i][0][\"one_hot_label\"])\n",
    "    one_hot_t = np.array(one_hot_t, dtype=np.float32)\n",
    "    one_hot_t = torch.from_numpy(one_hot_t)\n",
    "#     one_hot_t.cuda()\n",
    "    one_hot_t = Variable(one_hot_t)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    y = model(x)\n",
    "    loss = criterion(y, one_hot_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    _, pred = torch.max(y.data, 1)\n",
    "    _, answ = torch.max(one_hot_t.data, 1)\n",
    "    accuracy = (pred == answ).sum() / batch_size\n",
    "    \n",
    "    print(\"[batch %d (%d images)] learning rate: %f, loss: %f, accuracy: %f\" % (batch+1, (batch+1) * batch_size, optimizer.param_groups[0]['lr'], loss, accuracy))\n",
    "    \n",
    "    # update lr\n",
    "    optimizer = lr_scheduler(optimizer, batch, lr_decay_power) # Polynomial decay learning rate\n",
    "\n",
    "    # save model\n",
    "    if (batch+1) % 1000 == 0:\n",
    "        model_file = \"%s/%s.pth\" % (backup_path, batch+1)\n",
    "        print(\"saving model to %s\" % (model_file))\n",
    "        torch.save(model.state_dict(), model_file)\n",
    "\n",
    "print(\"saving model to %s/darknet19_final.model\" % (backup_path))\n",
    "torch.save(model.state_dict(), \"%s/darknet19_final.model\" % (backup_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-4.2.0]",
   "language": "python",
   "name": "conda-env-anaconda3-4.2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
